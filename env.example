# Specify an endpoint ID if not using an AzureML-enabled notebook
# or if running this code from a different workspace.
# Example format: "/subscriptions/{subscription-id}/resourceGroups/{resource-group}/providers/Microsoft.MachineLearningServices/workspaces/{workspace-name}/onlineEndpoints/{endpoint-name}"
# If the endpoint is in this workspace, you can simply specify its name, e.g., "medimageinsight-xyz"
MI2_MODEL_ENDPOINT = ""


# Specify an endpoint ID if not using an AzureML-enabled notebook
# or if running this code from a different workspace.
# Example format: "/subscriptions/{subscription-id}/resourceGroups/{resource-group}/providers/Microsoft.MachineLearningServices/workspaces/{workspace-name}/onlineEndpoints/{endpoint-name}"
# If the endpoint is in this workspace, you can simply specify its name, e.g., "medimageparse-xyz"
MIP_MODEL_ENDPOINT = ""


# Specify an endpoint ID if not using an AzureML-enabled notebook
# or if running this code from a different workspace.
# Example format: "/subscriptions/{subscription-id}/resourceGroups/{resource-group}/providers/Microsoft.MachineLearningServices/workspaces/{workspace-name}/onlineEndpoints/{endpoint-name}"
# If the endpoint is in this workspace, you can simply specify its name, e.g., "gigapath-xyz"
GIGAPATH_MODEL_ENDPOINT = ""

# Specify an endpoint ID if not using an AzureML-enabled notebook
# or if running this code from a different workspace.
# Example format: "/subscriptions/{subscription-id}/resourceGroups/{resource-group}/providers/Microsoft.MachineLearningServices/workspaces/{workspace-name}/onlineEndpoints/{endpoint-name}"
# If the endpoint is in this workspace, you can simply specify its name, e.g., "cxrreportgen-xyz"
CXRREPORTGEN_MODEL_ENDPOINT = ""

# Root directory for data storage (use absolute path)
DATA_ROOT = /home/azureuser/data/healthcare-ai/

# Azure OpenAI / GPT Configuration (Optional)
# You can specify either:
# 1. Full inference URI (includes deployment and API version):
#    AZURE_OPENAI_ENDPOINT = "https://{your-service}.cognitiveservices.azure.com/openai/deployments/{deployment-name}/chat/completions?api-version={api_version}"
# 2. Base endpoint with separate model configuration:
#    AZURE_OPENAI_ENDPOINT = "https://{your-service}.cognitiveservices.azure.com/"
#    AZURE_OPENAI_DEPLOYMENT_NAME = "gpt-4o"
# Required: API key for authentication
AZURE_OPENAI_ENDPOINT = ""